{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Handwritten digits dataset\n",
        "\n",
        "* -> [dataset](https://medium.com/mlearning-ai/mnist-dataset-of-handwritten-digits-f8cf28edafe)"
      ],
      "metadata": {
        "id": "dKlaz2OSp7G4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoxj7EKHqgVp",
        "outputId": "d9a33445-dc96-4521-c90c-8c66bdab1656"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading data and transforming it to tensors\n",
        "train_data = datasets.MNIST(root = 'data', train = True, transform = ToTensor(), download = True)\n",
        "# Test data simply as it is\n",
        "test_data = datasets.MNIST(root = 'data', train = False, transform = ToTensor(), download = True)"
      ],
      "metadata": {
        "id": "2MJXvkh-qu_r"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The data\n",
        "train_data, train_data.data.shape, train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fK75e5SzrEch",
        "outputId": "a24eff8a-43ac-48b2-aa7a-e30f909949ef"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset MNIST\n",
              "     Number of datapoints: 60000\n",
              "     Root location: data\n",
              "     Split: Train\n",
              "     StandardTransform\n",
              " Transform: ToTensor(),\n",
              " torch.Size([60000, 28, 28]),\n",
              " tensor([5, 0, 4,  ..., 5, 6, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loader = {\n",
        "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test': DataLoader(test_data, batch_size=100, shuffle=True, num_workers=1)\n",
        "}"
      ],
      "metadata": {
        "id": "X0RHwj8PrG76"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the model architecture\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__() # calling itself as a super constructor\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # conv layer1\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # conv layer2\n",
        "    self.conv2_drop = nn.Dropout2d() # dropout layer\n",
        "    self.fc1 = nn.Linear(320, 50) # fully connected layer\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2)) # The Rectified Linear Unit\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    # flattening the data\n",
        "    x = x.view(-1, 320) # 20x4x4\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x)"
      ],
      "metadata": {
        "id": "GcgirZeYscwI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device) # working on GPU\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01) # or SGD\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch): # epoch for logging\n",
        "  model.train()\n",
        "  for batch_index, (data, target) in enumerate(loader['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward() # backward it to backpropogate to store gradients in the tensors\n",
        "    optimizer.step()\n",
        "    if batch_index % 20 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_index * len(data)}/{len(loader[\"train\"].dataset)} ({100. * batch_index / len(loader[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad(): # disable grad calc\n",
        "    for data, target in loader['test']:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "  test_loss /= len(loader[\"train\"].dataset)\n",
        "  print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct}/{len(loader[\"train\"].dataset)} ({100. * correct / len(loader[\"train\"].dataset):.0f}%\\n)')"
      ],
      "metadata": {
        "id": "NZaM2MkSvm7M"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gsqaIxnyXJj",
        "outputId": "6ff777a3-ab2b-4996-ca32-bd8d834b1bf0"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-be47790e5fd0>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\t2.302053\n",
            "Train Epoch: 1 [2000/60000 (3%)]\t2.115432\n",
            "Train Epoch: 1 [4000/60000 (7%)]\t1.835226\n",
            "Train Epoch: 1 [6000/60000 (10%)]\t1.754271\n",
            "Train Epoch: 1 [8000/60000 (13%)]\t1.787698\n",
            "Train Epoch: 1 [10000/60000 (17%)]\t1.727607\n",
            "Train Epoch: 1 [12000/60000 (20%)]\t1.770287\n",
            "Train Epoch: 1 [14000/60000 (23%)]\t1.645606\n",
            "Train Epoch: 1 [16000/60000 (27%)]\t1.709121\n",
            "Train Epoch: 1 [18000/60000 (30%)]\t1.620206\n",
            "Train Epoch: 1 [20000/60000 (33%)]\t1.678094\n",
            "Train Epoch: 1 [22000/60000 (37%)]\t1.734790\n",
            "Train Epoch: 1 [24000/60000 (40%)]\t1.682721\n",
            "Train Epoch: 1 [26000/60000 (43%)]\t1.682519\n",
            "Train Epoch: 1 [28000/60000 (47%)]\t1.637746\n",
            "Train Epoch: 1 [30000/60000 (50%)]\t1.645975\n",
            "Train Epoch: 1 [32000/60000 (53%)]\t1.656120\n",
            "Train Epoch: 1 [34000/60000 (57%)]\t1.704613\n",
            "Train Epoch: 1 [36000/60000 (60%)]\t1.661657\n",
            "Train Epoch: 1 [38000/60000 (63%)]\t1.647623\n",
            "Train Epoch: 1 [40000/60000 (67%)]\t1.634174\n",
            "Train Epoch: 1 [42000/60000 (70%)]\t1.708295\n",
            "Train Epoch: 1 [44000/60000 (73%)]\t1.614123\n",
            "Train Epoch: 1 [46000/60000 (77%)]\t1.670644\n",
            "Train Epoch: 1 [48000/60000 (80%)]\t1.677260\n",
            "Train Epoch: 1 [50000/60000 (83%)]\t1.639220\n",
            "Train Epoch: 1 [52000/60000 (87%)]\t1.659362\n",
            "Train Epoch: 1 [54000/60000 (90%)]\t1.740918\n",
            "Train Epoch: 1 [56000/60000 (93%)]\t1.660302\n",
            "Train Epoch: 1 [58000/60000 (97%)]\t1.650602\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy 8923/60000 (15%\n",
            ")\n",
            "Train Epoch: 2 [0/60000 (0%)]\t1.788404\n",
            "Train Epoch: 2 [2000/60000 (3%)]\t1.691077\n",
            "Train Epoch: 2 [4000/60000 (7%)]\t1.721290\n",
            "Train Epoch: 2 [6000/60000 (10%)]\t1.630524\n",
            "Train Epoch: 2 [8000/60000 (13%)]\t1.645418\n",
            "Train Epoch: 2 [10000/60000 (17%)]\t1.652889\n",
            "Train Epoch: 2 [12000/60000 (20%)]\t1.720350\n",
            "Train Epoch: 2 [14000/60000 (23%)]\t1.769653\n",
            "Train Epoch: 2 [16000/60000 (27%)]\t1.760321\n",
            "Train Epoch: 2 [18000/60000 (30%)]\t1.681133\n",
            "Train Epoch: 2 [20000/60000 (33%)]\t1.771352\n",
            "Train Epoch: 2 [22000/60000 (37%)]\t1.699237\n",
            "Train Epoch: 2 [24000/60000 (40%)]\t1.700220\n",
            "Train Epoch: 2 [26000/60000 (43%)]\t1.718166\n",
            "Train Epoch: 2 [28000/60000 (47%)]\t1.762868\n",
            "Train Epoch: 2 [30000/60000 (50%)]\t1.843816\n",
            "Train Epoch: 2 [32000/60000 (53%)]\t1.772708\n",
            "Train Epoch: 2 [34000/60000 (57%)]\t1.761948\n",
            "Train Epoch: 2 [36000/60000 (60%)]\t1.720944\n",
            "Train Epoch: 2 [38000/60000 (63%)]\t1.770172\n",
            "Train Epoch: 2 [40000/60000 (67%)]\t1.741135\n",
            "Train Epoch: 2 [42000/60000 (70%)]\t1.742008\n",
            "Train Epoch: 2 [44000/60000 (73%)]\t1.771119\n",
            "Train Epoch: 2 [46000/60000 (77%)]\t1.720873\n",
            "Train Epoch: 2 [48000/60000 (80%)]\t1.687616\n",
            "Train Epoch: 2 [50000/60000 (83%)]\t1.691151\n",
            "Train Epoch: 2 [52000/60000 (87%)]\t1.731151\n",
            "Train Epoch: 2 [54000/60000 (90%)]\t1.708563\n",
            "Train Epoch: 2 [56000/60000 (93%)]\t1.941148\n",
            "Train Epoch: 2 [58000/60000 (97%)]\t1.702549\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy 9175/60000 (15%\n",
            ")\n",
            "Train Epoch: 3 [0/60000 (0%)]\t1.730554\n",
            "Train Epoch: 3 [2000/60000 (3%)]\t1.801076\n",
            "Train Epoch: 3 [4000/60000 (7%)]\t1.670848\n",
            "Train Epoch: 3 [6000/60000 (10%)]\t1.760926\n",
            "Train Epoch: 3 [8000/60000 (13%)]\t1.761133\n",
            "Train Epoch: 3 [10000/60000 (17%)]\t1.753320\n",
            "Train Epoch: 3 [12000/60000 (20%)]\t1.710819\n",
            "Train Epoch: 3 [14000/60000 (23%)]\t1.730985\n",
            "Train Epoch: 3 [16000/60000 (27%)]\t1.761156\n",
            "Train Epoch: 3 [18000/60000 (30%)]\t1.751150\n",
            "Train Epoch: 3 [20000/60000 (33%)]\t1.731143\n",
            "Train Epoch: 3 [22000/60000 (37%)]\t1.721146\n",
            "Train Epoch: 3 [24000/60000 (40%)]\t1.751040\n",
            "Train Epoch: 3 [26000/60000 (43%)]\t1.710348\n",
            "Train Epoch: 3 [28000/60000 (47%)]\t1.741151\n",
            "Train Epoch: 3 [30000/60000 (50%)]\t1.730768\n",
            "Train Epoch: 3 [32000/60000 (53%)]\t1.821104\n",
            "Train Epoch: 3 [34000/60000 (57%)]\t1.751148\n",
            "Train Epoch: 3 [36000/60000 (60%)]\t1.791483\n",
            "Train Epoch: 3 [38000/60000 (63%)]\t1.701096\n",
            "Train Epoch: 3 [40000/60000 (67%)]\t1.731151\n",
            "Train Epoch: 3 [42000/60000 (70%)]\t1.671144\n",
            "Train Epoch: 3 [44000/60000 (73%)]\t1.781175\n",
            "Train Epoch: 3 [46000/60000 (77%)]\t1.711170\n",
            "Train Epoch: 3 [48000/60000 (80%)]\t1.721151\n",
            "Train Epoch: 3 [50000/60000 (83%)]\t1.701086\n",
            "Train Epoch: 3 [52000/60000 (87%)]\t1.681249\n",
            "Train Epoch: 3 [54000/60000 (90%)]\t1.816020\n",
            "Train Epoch: 3 [56000/60000 (93%)]\t1.801064\n",
            "Train Epoch: 3 [58000/60000 (97%)]\t1.701151\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy 8519/60000 (14%\n",
            ")\n",
            "Train Epoch: 4 [0/60000 (0%)]\t1.861151\n",
            "Train Epoch: 4 [2000/60000 (3%)]\t1.811071\n",
            "Train Epoch: 4 [4000/60000 (7%)]\t1.713550\n",
            "Train Epoch: 4 [6000/60000 (10%)]\t1.729985\n",
            "Train Epoch: 4 [8000/60000 (13%)]\t1.737924\n",
            "Train Epoch: 4 [10000/60000 (17%)]\t1.770878\n",
            "Train Epoch: 4 [12000/60000 (20%)]\t1.790812\n",
            "Train Epoch: 4 [14000/60000 (23%)]\t1.851134\n",
            "Train Epoch: 4 [16000/60000 (27%)]\t1.721151\n",
            "Train Epoch: 4 [18000/60000 (30%)]\t1.771151\n",
            "Train Epoch: 4 [20000/60000 (33%)]\t1.681285\n",
            "Train Epoch: 4 [22000/60000 (37%)]\t1.711158\n",
            "Train Epoch: 4 [24000/60000 (40%)]\t1.741151\n",
            "Train Epoch: 4 [26000/60000 (43%)]\t1.661151\n",
            "Train Epoch: 4 [28000/60000 (47%)]\t1.731151\n",
            "Train Epoch: 4 [30000/60000 (50%)]\t1.801826\n",
            "Train Epoch: 4 [32000/60000 (53%)]\t1.871166\n",
            "Train Epoch: 4 [34000/60000 (57%)]\t1.731151\n",
            "Train Epoch: 4 [36000/60000 (60%)]\t1.831094\n",
            "Train Epoch: 4 [38000/60000 (63%)]\t1.720919\n",
            "Train Epoch: 4 [40000/60000 (67%)]\t1.801151\n",
            "Train Epoch: 4 [42000/60000 (70%)]\t1.750980\n",
            "Train Epoch: 4 [44000/60000 (73%)]\t1.771151\n",
            "Train Epoch: 4 [46000/60000 (77%)]\t1.741151\n",
            "Train Epoch: 4 [48000/60000 (80%)]\t1.811151\n",
            "Train Epoch: 4 [50000/60000 (83%)]\t1.841151\n",
            "Train Epoch: 4 [52000/60000 (87%)]\t1.791151\n",
            "Train Epoch: 4 [54000/60000 (90%)]\t1.751151\n",
            "Train Epoch: 4 [56000/60000 (93%)]\t1.751159\n",
            "Train Epoch: 4 [58000/60000 (97%)]\t1.741151\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy 8747/60000 (15%\n",
            ")\n",
            "Train Epoch: 5 [0/60000 (0%)]\t1.781929\n",
            "Train Epoch: 5 [2000/60000 (3%)]\t1.721151\n",
            "Train Epoch: 5 [4000/60000 (7%)]\t1.771141\n",
            "Train Epoch: 5 [6000/60000 (10%)]\t1.789970\n",
            "Train Epoch: 5 [8000/60000 (13%)]\t1.761151\n",
            "Train Epoch: 5 [10000/60000 (17%)]\t1.911151\n",
            "Train Epoch: 5 [12000/60000 (20%)]\t1.861151\n",
            "Train Epoch: 5 [14000/60000 (23%)]\t1.781151\n",
            "Train Epoch: 5 [16000/60000 (27%)]\t1.721518\n",
            "Train Epoch: 5 [18000/60000 (30%)]\t1.671152\n",
            "Train Epoch: 5 [20000/60000 (33%)]\t1.691151\n",
            "Train Epoch: 5 [22000/60000 (37%)]\t1.761151\n",
            "Train Epoch: 5 [24000/60000 (40%)]\t1.716026\n",
            "Train Epoch: 5 [26000/60000 (43%)]\t1.731151\n",
            "Train Epoch: 5 [28000/60000 (47%)]\t1.694328\n",
            "Train Epoch: 5 [30000/60000 (50%)]\t1.941147\n",
            "Train Epoch: 5 [32000/60000 (53%)]\t1.851151\n",
            "Train Epoch: 5 [34000/60000 (57%)]\t1.821151\n",
            "Train Epoch: 5 [36000/60000 (60%)]\t1.701151\n",
            "Train Epoch: 5 [38000/60000 (63%)]\t1.818064\n",
            "Train Epoch: 5 [40000/60000 (67%)]\t1.831151\n",
            "Train Epoch: 5 [42000/60000 (70%)]\t1.751151\n",
            "Train Epoch: 5 [44000/60000 (73%)]\t1.791151\n",
            "Train Epoch: 5 [46000/60000 (77%)]\t1.808199\n",
            "Train Epoch: 5 [48000/60000 (80%)]\t1.721145\n",
            "Train Epoch: 5 [50000/60000 (83%)]\t1.691150\n",
            "Train Epoch: 5 [52000/60000 (87%)]\t1.720815\n",
            "Train Epoch: 5 [54000/60000 (90%)]\t1.761173\n",
            "Train Epoch: 5 [56000/60000 (93%)]\t1.810465\n",
            "Train Epoch: 5 [58000/60000 (97%)]\t1.851151\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy 8180/60000 (14%\n",
            ")\n",
            "Train Epoch: 6 [0/60000 (0%)]\t1.781151\n",
            "Train Epoch: 6 [2000/60000 (3%)]\t1.801151\n",
            "Train Epoch: 6 [4000/60000 (7%)]\t1.791151\n",
            "Train Epoch: 6 [6000/60000 (10%)]\t1.831164\n",
            "Train Epoch: 6 [8000/60000 (13%)]\t1.740715\n",
            "Train Epoch: 6 [10000/60000 (17%)]\t1.731119\n",
            "Train Epoch: 6 [12000/60000 (20%)]\t1.771123\n",
            "Train Epoch: 6 [14000/60000 (23%)]\t1.721151\n",
            "Train Epoch: 6 [16000/60000 (27%)]\t1.681127\n",
            "Train Epoch: 6 [18000/60000 (30%)]\t1.751151\n",
            "Train Epoch: 6 [20000/60000 (33%)]\t1.811151\n",
            "Train Epoch: 6 [22000/60000 (37%)]\t1.721151\n",
            "Train Epoch: 6 [24000/60000 (40%)]\t1.691151\n",
            "Train Epoch: 6 [26000/60000 (43%)]\t1.741151\n",
            "Train Epoch: 6 [28000/60000 (47%)]\t1.731139\n",
            "Train Epoch: 6 [30000/60000 (50%)]\t1.761151\n",
            "Train Epoch: 6 [32000/60000 (53%)]\t1.689807\n",
            "Train Epoch: 6 [34000/60000 (57%)]\t1.771151\n",
            "Train Epoch: 6 [36000/60000 (60%)]\t1.771151\n",
            "Train Epoch: 6 [38000/60000 (63%)]\t1.681677\n",
            "Train Epoch: 6 [40000/60000 (67%)]\t1.761146\n",
            "Train Epoch: 6 [42000/60000 (70%)]\t1.711266\n",
            "Train Epoch: 6 [44000/60000 (73%)]\t1.771411\n",
            "Train Epoch: 6 [46000/60000 (77%)]\t1.811151\n",
            "Train Epoch: 6 [48000/60000 (80%)]\t1.771150\n",
            "Train Epoch: 6 [50000/60000 (83%)]\t1.771094\n",
            "Train Epoch: 6 [52000/60000 (87%)]\t1.791894\n",
            "Train Epoch: 6 [54000/60000 (90%)]\t1.761151\n",
            "Train Epoch: 6 [56000/60000 (93%)]\t1.751151\n",
            "Train Epoch: 6 [58000/60000 (97%)]\t1.771151\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy 8795/60000 (15%\n",
            ")\n",
            "Train Epoch: 7 [0/60000 (0%)]\t1.781151\n",
            "Train Epoch: 7 [2000/60000 (3%)]\t1.791151\n",
            "Train Epoch: 7 [4000/60000 (7%)]\t1.769191\n",
            "Train Epoch: 7 [6000/60000 (10%)]\t1.641150\n",
            "Train Epoch: 7 [8000/60000 (13%)]\t1.621151\n",
            "Train Epoch: 7 [10000/60000 (17%)]\t1.711151\n",
            "Train Epoch: 7 [12000/60000 (20%)]\t1.751151\n",
            "Train Epoch: 7 [14000/60000 (23%)]\t1.750995\n",
            "Train Epoch: 7 [16000/60000 (27%)]\t1.851151\n",
            "Train Epoch: 7 [18000/60000 (30%)]\t1.732598\n",
            "Train Epoch: 7 [20000/60000 (33%)]\t1.780946\n",
            "Train Epoch: 7 [22000/60000 (37%)]\t1.698239\n",
            "Train Epoch: 7 [24000/60000 (40%)]\t1.701581\n",
            "Train Epoch: 7 [26000/60000 (43%)]\t1.731060\n",
            "Train Epoch: 7 [28000/60000 (47%)]\t1.841118\n",
            "Train Epoch: 7 [30000/60000 (50%)]\t1.841151\n",
            "Train Epoch: 7 [32000/60000 (53%)]\t1.781151\n",
            "Train Epoch: 7 [34000/60000 (57%)]\t1.741214\n",
            "Train Epoch: 7 [36000/60000 (60%)]\t1.791149\n",
            "Train Epoch: 7 [38000/60000 (63%)]\t1.761151\n",
            "Train Epoch: 7 [40000/60000 (67%)]\t1.741151\n",
            "Train Epoch: 7 [42000/60000 (70%)]\t1.721151\n",
            "Train Epoch: 7 [44000/60000 (73%)]\t1.731151\n",
            "Train Epoch: 7 [46000/60000 (77%)]\t1.841151\n",
            "Train Epoch: 7 [48000/60000 (80%)]\t1.931239\n",
            "Train Epoch: 7 [50000/60000 (83%)]\t1.811151\n",
            "Train Epoch: 7 [52000/60000 (87%)]\t1.901146\n",
            "Train Epoch: 7 [54000/60000 (90%)]\t1.851151\n",
            "Train Epoch: 7 [56000/60000 (93%)]\t1.831188\n",
            "Train Epoch: 7 [58000/60000 (97%)]\t1.821151\n",
            "\n",
            "Test set: Average loss: 0.0028, Accuracy 8069/60000 (13%\n",
            ")\n",
            "Train Epoch: 8 [0/60000 (0%)]\t1.751151\n",
            "Train Epoch: 8 [2000/60000 (3%)]\t1.831151\n",
            "Train Epoch: 8 [4000/60000 (7%)]\t1.781150\n",
            "Train Epoch: 8 [6000/60000 (10%)]\t1.711151\n",
            "Train Epoch: 8 [8000/60000 (13%)]\t1.811151\n",
            "Train Epoch: 8 [10000/60000 (17%)]\t1.761151\n",
            "Train Epoch: 8 [12000/60000 (20%)]\t1.761151\n",
            "Train Epoch: 8 [14000/60000 (23%)]\t1.722181\n",
            "Train Epoch: 8 [16000/60000 (27%)]\t1.732192\n",
            "Train Epoch: 8 [18000/60000 (30%)]\t1.791151\n",
            "Train Epoch: 8 [20000/60000 (33%)]\t1.741151\n",
            "Train Epoch: 8 [22000/60000 (37%)]\t1.841238\n",
            "Train Epoch: 8 [24000/60000 (40%)]\t1.791151\n",
            "Train Epoch: 8 [26000/60000 (43%)]\t1.711151\n",
            "Train Epoch: 8 [28000/60000 (47%)]\t1.831151\n",
            "Train Epoch: 8 [30000/60000 (50%)]\t1.771151\n",
            "Train Epoch: 8 [32000/60000 (53%)]\t1.811151\n",
            "Train Epoch: 8 [34000/60000 (57%)]\t1.751151\n",
            "Train Epoch: 8 [36000/60000 (60%)]\t1.801151\n",
            "Train Epoch: 8 [38000/60000 (63%)]\t1.851151\n",
            "Train Epoch: 8 [40000/60000 (67%)]\t1.861151\n",
            "Train Epoch: 8 [42000/60000 (70%)]\t1.761151\n",
            "Train Epoch: 8 [44000/60000 (73%)]\t1.821151\n",
            "Train Epoch: 8 [46000/60000 (77%)]\t1.831121\n",
            "Train Epoch: 8 [48000/60000 (80%)]\t1.871150\n",
            "Train Epoch: 8 [50000/60000 (83%)]\t1.821151\n",
            "Train Epoch: 8 [52000/60000 (87%)]\t1.871151\n",
            "Train Epoch: 8 [54000/60000 (90%)]\t1.801151\n",
            "Train Epoch: 8 [56000/60000 (93%)]\t1.811151\n",
            "Train Epoch: 8 [58000/60000 (97%)]\t1.841159\n",
            "\n",
            "Test set: Average loss: 0.0029, Accuracy 7134/60000 (12%\n",
            ")\n",
            "Train Epoch: 9 [0/60000 (0%)]\t1.871294\n",
            "Train Epoch: 9 [2000/60000 (3%)]\t1.861151\n",
            "Train Epoch: 9 [4000/60000 (7%)]\t1.911109\n",
            "Train Epoch: 9 [6000/60000 (10%)]\t1.971151\n",
            "Train Epoch: 9 [8000/60000 (13%)]\t1.991151\n",
            "Train Epoch: 9 [10000/60000 (17%)]\t1.961150\n",
            "Train Epoch: 9 [12000/60000 (20%)]\t1.931075\n",
            "Train Epoch: 9 [14000/60000 (23%)]\t1.911151\n",
            "Train Epoch: 9 [16000/60000 (27%)]\t1.961151\n",
            "Train Epoch: 9 [18000/60000 (30%)]\t1.841151\n",
            "Train Epoch: 9 [20000/60000 (33%)]\t1.851151\n",
            "Train Epoch: 9 [22000/60000 (37%)]\t1.831151\n",
            "Train Epoch: 9 [24000/60000 (40%)]\t1.811151\n",
            "Train Epoch: 9 [26000/60000 (43%)]\t1.771161\n",
            "Train Epoch: 9 [28000/60000 (47%)]\t1.821151\n",
            "Train Epoch: 9 [30000/60000 (50%)]\t1.791141\n",
            "Train Epoch: 9 [32000/60000 (53%)]\t1.831151\n",
            "Train Epoch: 9 [34000/60000 (57%)]\t1.791107\n",
            "Train Epoch: 9 [36000/60000 (60%)]\t1.701151\n",
            "Train Epoch: 9 [38000/60000 (63%)]\t1.781151\n",
            "Train Epoch: 9 [40000/60000 (67%)]\t1.771115\n",
            "Train Epoch: 9 [42000/60000 (70%)]\t1.811151\n",
            "Train Epoch: 9 [44000/60000 (73%)]\t1.781151\n",
            "Train Epoch: 9 [46000/60000 (77%)]\t1.791151\n",
            "Train Epoch: 9 [48000/60000 (80%)]\t1.761151\n",
            "Train Epoch: 9 [50000/60000 (83%)]\t1.741149\n",
            "Train Epoch: 9 [52000/60000 (87%)]\t1.861151\n",
            "Train Epoch: 9 [54000/60000 (90%)]\t1.931921\n",
            "Train Epoch: 9 [56000/60000 (93%)]\t1.801151\n",
            "Train Epoch: 9 [58000/60000 (97%)]\t1.781151\n",
            "\n",
            "Test set: Average loss: 0.0027, Accuracy 8603/60000 (14%\n",
            ")\n",
            "Train Epoch: 10 [0/60000 (0%)]\t1.811151\n",
            "Train Epoch: 10 [2000/60000 (3%)]\t1.829835\n",
            "Train Epoch: 10 [4000/60000 (7%)]\t1.861151\n",
            "Train Epoch: 10 [6000/60000 (10%)]\t1.901151\n",
            "Train Epoch: 10 [8000/60000 (13%)]\t1.791151\n",
            "Train Epoch: 10 [10000/60000 (17%)]\t1.800396\n",
            "Train Epoch: 10 [12000/60000 (20%)]\t1.691151\n",
            "Train Epoch: 10 [14000/60000 (23%)]\t1.831151\n",
            "Train Epoch: 10 [16000/60000 (27%)]\t1.731151\n",
            "Train Epoch: 10 [18000/60000 (30%)]\t1.731151\n",
            "Train Epoch: 10 [20000/60000 (33%)]\t1.721151\n",
            "Train Epoch: 10 [22000/60000 (37%)]\t1.771151\n",
            "Train Epoch: 10 [24000/60000 (40%)]\t1.761151\n",
            "Train Epoch: 10 [26000/60000 (43%)]\t1.711151\n",
            "Train Epoch: 10 [28000/60000 (47%)]\t1.711151\n",
            "Train Epoch: 10 [30000/60000 (50%)]\t1.752762\n",
            "Train Epoch: 10 [32000/60000 (53%)]\t1.781151\n",
            "Train Epoch: 10 [34000/60000 (57%)]\t1.901110\n",
            "Train Epoch: 10 [36000/60000 (60%)]\t1.831151\n",
            "Train Epoch: 10 [38000/60000 (63%)]\t1.851151\n",
            "Train Epoch: 10 [40000/60000 (67%)]\t1.751151\n",
            "Train Epoch: 10 [42000/60000 (70%)]\t1.811151\n",
            "Train Epoch: 10 [44000/60000 (73%)]\t1.861268\n",
            "Train Epoch: 10 [46000/60000 (77%)]\t1.811016\n",
            "Train Epoch: 10 [48000/60000 (80%)]\t1.970964\n",
            "Train Epoch: 10 [50000/60000 (83%)]\t1.901151\n",
            "Train Epoch: 10 [52000/60000 (87%)]\t1.811151\n",
            "Train Epoch: 10 [54000/60000 (90%)]\t1.811151\n",
            "Train Epoch: 10 [56000/60000 (93%)]\t1.841151\n",
            "Train Epoch: 10 [58000/60000 (97%)]\t1.691151\n",
            "\n",
            "Test set: Average loss: 0.0026, Accuracy 8901/60000 (15%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "data, target = test_data[12]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "vJ_LmX1J-Qcr",
        "outputId": "b87f28db-64cb-4915-fb1a-1d23ac70cdf2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-63-be47790e5fd0>:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}